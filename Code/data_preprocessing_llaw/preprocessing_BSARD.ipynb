{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Pretrain_:\n",
    "\n",
    "Pretrain data corresponds to plain text data stored in the `\"text\"` key. E.g:\n",
    "\n",
    "```jsonl\n",
    "{\"text\": \"Text contained in document n°1\"}\n",
    "{\"text\": \"Text contained in document n°2\"}\n",
    "```\n",
    "\n",
    "### _Instruct_:\n",
    "\n",
    "Currently two different types of instruction following data are supported:\n",
    "\n",
    "- _Instruct_: conversational data stored in the `\"messages\"` key in the form of a list. Each list item is a dictionary containing the `\"content\"` and `\"role\"` keys. `\"role\"` is a string being one of \"user\", \"assistant\" or \"system\". The loss will only be computed if \"role\" == \"assistant\". E.g.:\n",
    "\n",
    "```jsonl\n",
    "{\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"User interaction n°1 contained in document n°1\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"Bot interaction n°1 contained in document n°1\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"User interaction n°2 contained in document n°1\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"Bot interaction n°2 contained in document n°1\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start with the data we already have, then we can check for more data later on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\n",
    "    \"/Users/naimsassine/Desktop/DS & AI/BelgianLaw Finetuning/Data/synthetic.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's prompt chatgpt to get the answers to my questionss!\n",
    "test = test.sample(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = \"\"\n",
    "openai.api_base = \"\"\n",
    "openai.api_version = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(question, model=\"gpt-4\"):\n",
    "    prompt = \"Tu es un assistant avec des connaissances approfondies dans le milieu légal Belge. Je veux que tu répondes à la question suivante qui réside dans le contexte légal Belge en maximum 2-3 lignes, pas plus, avec les justifications nécessaires.\"\n",
    "    full_prompt = f\"{prompt}\\n\\n{question}\"\n",
    "\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": full_prompt},\n",
    "            ],\n",
    "            deployment_id=model,\n",
    "        )\n",
    "        return response.choices[0].message[\"content\"].strip()\n",
    "    except openai.OpenAIError as e:\n",
    "        return f\"An error occurred: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "question = (\n",
    "    \"Quels sont les droits des travailleurs en Belgique concernant les congés annuels?\"\n",
    ")\n",
    "\n",
    "\n",
    "generated_text = generate_text(question)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.extra_description = test.extra_description.fillna(\"pas d'information en plus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"detailed_question\"] = test.question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"detailed_question\"] = test.apply(\n",
    "    lambda x: x[\"question\"]\n",
    "    + \". En sachant que la categorie de la question est : \"\n",
    "    + x[\"subcategory\"]\n",
    "    + \" et voici une information en plus par rapport à la question: \"\n",
    "    + x[\"extra_description\"],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Un conseiller peut exécuter une réclamation à l'administration belge lorsqu'il identifie une violation des droits ou des intérêts légitimes d'un individu ou d'une entreprise, et ce, conformément aux procédures légales en vigueur (par exemple, dans le cadre d'un recours administratif).\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(test[\"detailed_question\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answers_and_write_to_file(df, question_column, output_file):\n",
    "    with open(output_file, \"w\") as file:\n",
    "        for index, row in df.iterrows():\n",
    "            question = row[question_column]\n",
    "            answer = generate_text(question)\n",
    "            file.write(f\"Question: {question}\\nAnswer: {answer}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_answers_and_write_to_file(test, \"detailed_question\", \"answers_synthet.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_qa_file(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "    questions = []\n",
    "    answers = []\n",
    "\n",
    "    qa_pairs = content.split(\"\\n\\n\")\n",
    "\n",
    "    for pair in qa_pairs:\n",
    "        if pair.strip():\n",
    "            question_part, answer_part = pair.split(\"Answer:\", 1)\n",
    "            question = question_part.replace(\"Question:\", \"\").strip()\n",
    "            answer = answer_part.strip()\n",
    "            questions.append(question)\n",
    "            answers.append(answer)\n",
    "\n",
    "    df = pd.DataFrame({\"Question\": questions, \"Answer\": answers})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parse_qa_file(\"answers_synthet.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Question\": \"question\", \"Answer\": \"answer\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process\n",
    "\n",
    "\n",
    "# Function to perform fuzzy matching and merge dataframes\n",
    "def fuzzy_merge(df1, df2, key1, key2, threshold=90, limit=1):\n",
    "    \"\"\"\n",
    "    df1, df2: Dataframes to be merged\n",
    "    key1, key2: Column names to match on\n",
    "    threshold: Score above which to consider it a match\n",
    "    limit: Number of matches to return, using 1 for the best match\n",
    "    \"\"\"\n",
    "    s = df2[key2].tolist()\n",
    "\n",
    "    matches = df1[key1].apply(\n",
    "        lambda x: process.extractOne(x, s, score_cutoff=threshold)\n",
    "    )\n",
    "\n",
    "    df1[\"match\"] = matches\n",
    "    df1[\"match_score\"] = df1[\"match\"].apply(lambda x: x[1] if x is not None else None)\n",
    "    df1[\"match\"] = df1[\"match\"].apply(lambda x: x[0] if x is not None else None)\n",
    "\n",
    "    merged_df = df1.merge(df2, left_on=\"match\", right_on=key2, how=\"left\")\n",
    "    merged_df = merged_df.drop(columns=[\"match\", \"match_score\"])\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "# Use the fuzzy_merge function to merge the dataframes\n",
    "merged_df = fuzzy_merge(test, df, \"question\", \"question\", threshold=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df[merged_df.answer.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"synth_QA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
